{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "import urllib2\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from pandas import DataFrame, Series\n",
      "import datetime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###Put inputs here\n",
      "query = \"BMW Winter Wheels\"\n",
      "cities = ['chicago',\n",
      "          'indianapolis',\n",
      "          'columbus']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url_http = r\"http://\"\n",
      "url_start = r\".craigslist.org\"\n",
      "url_search = r\"/search/sss?query=\"\n",
      "url_end = r\"&sort=rel\"\n",
      "\n",
      "\n",
      "def process_query(query):\n",
      "    query = query.strip()\n",
      "    query = query.replace(\" \", \"%20\")\n",
      "    return query\n",
      "\n",
      "\n",
      "def all_search_urls():\n",
      "    final_urls = []\n",
      "    for city in cities:\n",
      "        next_city = {}\n",
      "        next_city['base_url'] = url_http + city + url_start \n",
      "        next_city['url'] = next_city['base_url'] + url_search + process_query(query) + url_end\n",
      "        final_urls.append(next_city)\n",
      "    return final_urls\n",
      "\n",
      "today_dt = datetime.datetime.now()\n",
      "format_date = today_dt.strftime('%Y-%m-%d')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def product_details(l_soup, base_url):\n",
      "    \"\"\"\n",
      "    Grabs a list of relevant details for the product and returns a dictionary.\n",
      "    \"\"\"\n",
      "    prod_dets = {}\n",
      "    url_start = base_url\n",
      "    \n",
      "    prod_dets['post_title'] = l_soup.find('a', class_=\"hdrlnk\").contents[0]\n",
      "    prod_dets['post_url'] = url_start + l_soup.find('a', class_=\"hdrlnk\")['href']\n",
      "    prod_dets['post_date'] = l_soup.find('time')['datetime']\n",
      "    \n",
      "    ##Attempting to Grab the Price of a Craigslist Item\n",
      "    post_price = l_soup.find('span', class_=\"price\")\n",
      "    if post_price != None:\n",
      "        post_price = post_price.contents[0]\n",
      "    prod_dets['post_price'] = post_price\n",
      "    \n",
      "    post_loc = l_soup.find('span', class_=\"pnr\").find('small')\n",
      "    if post_loc != None:\n",
      "        post_loc = post_loc.contents[0]\n",
      "    prod_dets['post_loc'] = post_loc\n",
      "    \n",
      "    return prod_dets    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def return_all_city_results(start_url, base_url):\n",
      "    \"\"\"\n",
      "    Scans the results of the start_url returns all the results to a list.\n",
      "    \"\"\"\n",
      "    exists_next_page = 1\n",
      "    next_url = start_url\n",
      "    product_listings = []\n",
      "    base_start = base_url\n",
      "    \n",
      "    while exists_next_page:\n",
      "        print \"Now Scanning\", next_url\n",
      "        response = urllib2.urlopen(next_url)\n",
      "        html = response.read()\n",
      "        response.close()\n",
      "        \n",
      "        soup = BeautifulSoup(html)\n",
      "        product_list = soup.find('div', class_=\"content\")\n",
      "        list_of_products = product_list.findAll('p', class_=\"row\")\n",
      "        \n",
      "        for next_product in list_of_products:\n",
      "            details = product_details(next_product, base_start)\n",
      "            product_listings.append(details)       \n",
      "\n",
      "        ##Checks if the Number of results is less than 100\n",
      "        ##If so, end the while loop\n",
      "        ##Else create the next url to be scanned\n",
      "        if len(list_of_products) < 100:\n",
      "            exists_next_page = 0\n",
      "        else:\n",
      "            next_url = base_start + soup.find('a', class_=\"button next\")['href']\n",
      "        \n",
      "    \n",
      "    return product_listings"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def main():\n",
      "    urls_to_search = all_search_urls()\n",
      "    results = []\n",
      "    for url_dict in urls_to_search:\n",
      "        base_url = url_dict['base_url']\n",
      "        url = url_dict['url']\n",
      "        next_results = return_all_city_results(url, base_url)\n",
      "        results += next_results\n",
      "    return DataFrame(results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bmw_results = main()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Now Scanning http://chicago.craigslist.org/search/sss?query=BMW%20Winter%20Wheels&sort=rel\n",
        "Now Scanning"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " http://chicago.craigslist.org/search/sss?s=100&query=BMW%20Winter%20Wheels&sort=rel\n",
        "Now Scanning"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " http://indianapolis.craigslist.org/search/sss?query=BMW%20Winter%20Wheels&sort=rel\n",
        "Now Scanning"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " http://columbus.craigslist.org/search/sss?query=BMW%20Winter%20Wheels&sort=rel\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "csv_file_name = query + \" \" + format_date + \".csv\"\n",
      "bmw_results.to_csv(csv_file_name, index=False, encoding='utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}